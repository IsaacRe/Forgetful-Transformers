{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa24bdcb-cfe5-4e1b-aa1c-4c15a0fc965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d0f022-f5db-4356-b98a-0d8bfd911e80",
   "metadata": {},
   "source": [
    "### Approximating within-softmax QK decomposition to bring dimensionality reduction outside softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d3c0b69a-05eb-47ae-a5fe-7007f8d2085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_ratio = 1  # test how error increases as Q becomes less PSD\n",
    "d = 64\n",
    "e = 200\n",
    "l = 400\n",
    "assert l >= d\n",
    "arange_d = torch.arange(d, 0, -1)\n",
    "psd_matrix = torch.Tensor(np.random.rand(d, d))\n",
    "psd_matrix = torch.matmul(psd_matrix, psd_matrix)\n",
    "psd_matrix = torch.cat([psd_matrix, torch.ones(l - d, d)], dim=0)\n",
    "q = torch.Tensor(np.random.rand(l, d)) * (1 - psd_ratio) + psd_matrix * psd_ratio\n",
    "q_inv = torch.linalg.pinv(q)\n",
    "k = torch.Tensor(np.random.rand(l, d)) * (1 - psd_ratio) + psd_matrix * psd_ratio\n",
    "\n",
    "# make sure query vectors are not all zero (creates large error when solving for K_hat, and will never occur in practice)\n",
    "\n",
    "q, k = q.type(torch.float), k.type(torch.float)\n",
    "v = torch.Tensor(np.random.rand(l, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "82ff216f-42ba-4511-a513-02ebfb933175",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.softmax(q @ k.T, dim=-1)\n",
    "out = A @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "027ed76a-84cf-42dc-bb89-6e58fc29e85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[ 6.1396e-09, -3.1815e-08,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-5.8241e-08,  2.2453e-05,  1.4986e-13,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 3.1224e-09,  1.0219e-06,  7.5583e-08,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 3.1224e-09,  1.0219e-06,  1.9642e-14,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 3.1224e-09,  1.0219e-06,  1.9642e-14,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 3.1224e-09,  1.0219e-06,  1.9642e-14,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decompose A into USD\n",
    "U, s, D = torch.linalg.svd(A)\n",
    "S = torch.diag(s)\n",
    "\n",
    "# take highest singular value vectors\n",
    "U = U[:,:e]\n",
    "S = S[:e,:e]\n",
    "D = D[:e,:]\n",
    "\n",
    "(A, U @ S @ D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "05d6ce37-954b-4b65-a029-c63d4affd9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute pseudo A\n",
    "US = U @ S\n",
    "\n",
    "# compute log offset\n",
    "offset = 1 - US.min()\n",
    "US_ = US + offset\n",
    "M_offset = torch.linalg.lstsq(US_, US).solution\n",
    "\n",
    "# make rows of pseudo A sum to 1\n",
    "rowsum = US_.sum(dim=-1)\n",
    "A_hat = US_ / rowsum[:,None]\n",
    "\n",
    "# compute V_hat\n",
    "V_hat = M_offset @ D @ v\n",
    "(A, US_ @ M_offset @ D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a7308059-520e-469d-988b-32fd2438350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.9315e-01, -5.9605e-08,  1.0729e-06,  ...,  1.0729e-06,\n",
       "           1.0729e-06,  1.0729e-06],\n",
       "         [ 6.9315e-01,  2.2411e-05,  1.0729e-06,  ...,  1.0729e-06,\n",
       "           1.0729e-06,  1.0729e-06],\n",
       "         [ 6.9315e-01,  1.0729e-06,  9.5367e-07,  ...,  1.0729e-06,\n",
       "           1.0729e-06,  1.0729e-06],\n",
       "         ...,\n",
       "         [ 6.9315e-01,  1.0729e-06,  1.0729e-06,  ...,  1.0729e-06,\n",
       "           1.0729e-06,  1.0729e-06],\n",
       "         [ 6.9315e-01,  1.0729e-06,  1.0729e-06,  ...,  1.0729e-06,\n",
       "           1.0729e-06,  1.0729e-06],\n",
       "         [ 6.9315e-01,  1.0729e-06,  1.0729e-06,  ...,  1.0729e-06,\n",
       "           1.0729e-06,  1.0729e-06]]),\n",
       " tensor([[6.9587e-01, 1.4325e-07, 1.0771e-06,  ..., 1.0774e-06, 1.0774e-06,\n",
       "          1.0774e-06],\n",
       "         [6.8875e-01, 2.2121e-05, 1.0661e-06,  ..., 1.0656e-06, 1.0655e-06,\n",
       "          1.0655e-06],\n",
       "         [6.9417e-01, 1.1348e-06, 9.5517e-07,  ..., 1.0745e-06, 1.0745e-06,\n",
       "          1.0745e-06],\n",
       "         ...,\n",
       "         [6.9314e-01, 1.0727e-06, 1.0729e-06,  ..., 1.0764e-06, 1.0764e-06,\n",
       "          1.0764e-06],\n",
       "         [6.9314e-01, 1.0727e-06, 1.0729e-06,  ..., 1.0764e-06, 1.0764e-06,\n",
       "          1.0764e-06],\n",
       "         [6.9314e-01, 1.0727e-06, 1.0729e-06,  ..., 1.0764e-06, 1.0764e-06,\n",
       "          1.0764e-06]]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solve for K_hat\n",
    "K_hat = torch.linalg.lstsq(q, torch.log(US_)).solution.T\n",
    "(torch.log(US_), q @ K_hat.T)  # overdetermined system when l > d (always)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6355d2ee-7331-4b8d-82cc-c2a4778e877b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
       "         [0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
       "         [0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
       "         ...,\n",
       "         [0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
       "         [0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
       "         [0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050]]),\n",
       " tensor([[0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
       "         [0.0099, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
       "         [0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
       "         ...,\n",
       "         [0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
       "         [0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050],\n",
       "         [0.0100, 0.0050, 0.0050,  ..., 0.0050, 0.0050, 0.0050]]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recompute A prime\n",
    "A_hat_p = torch.softmax(q @ K_hat.T, dim=-1)\n",
    "(A_hat, A_hat_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cfbf8689-8522-427e-a558-0a0d483fd349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " tensor([[2.9766e-09, 1.0729e-06, 2.3209e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9764e-09, 1.0728e-06, 2.3207e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.9765e-09, 1.0729e-06, 2.3208e-15,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruct original attention matrix\n",
    "A_p = (A_hat @ M_offset @ D) * rowsum[:,None]\n",
    "A_pp = (A_hat_p @ M_offset @ D) * rowsum[:,None]\n",
    "(A, A_p, A_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1bff4c5e-7993-4755-aef2-22a5a3fde12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2497e-05)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute new outputs\n",
    "out_p = (A_hat @ V_hat) * rowsum[:,None]\n",
    "out_pp = (A_hat_p @ V_hat) * rowsum[:,None]\n",
    "(out, out_p, out_pp)\n",
    "(((out - out_pp) ** 2).sum(dim=-1) ** 0.5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e036c4-e057-44e8-990f-37905f9f17bf",
   "metadata": {},
   "source": [
    "### Potential issues\n",
    "- Recomputing softmax for A_pp without original scaling factor of A_p\n",
    "- Scaling in alpha and inverse alpha at different points where they dont cancel\n",
    "- All-zero query vectors will make solving for K_hat ineffective\n",
    "- Q x K_hat = A_hat is overdetermined for K_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383fc67-8b6c-4406-be87-37f0322e1ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
