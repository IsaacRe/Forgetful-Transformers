{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa24bdcb-cfe5-4e1b-aa1c-4c15a0fc965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d0f022-f5db-4356-b98a-0d8bfd911e80",
   "metadata": {},
   "source": [
    "### Approximating within-softmax QK decomposition to bring dimensionality reduction outside softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b7ac8-6a5c-4024-8502-62d18691ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we approximate e^(AB) with e^A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7281e7cf-b2df-4432-902a-6e10cd926a16",
   "metadata": {},
   "source": [
    "### Can we approximate normalization coefficient of eigen-decomp attention matrix with that of original attention matrix?\n",
    "If attention eigenvalue mass is preserved, and the eigen-attention matrix is faithful approximation, total attention mass per token should be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657830d-a9d5-4c93-891b-3442a2da0757",
   "metadata": {},
   "source": [
    "### Second Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7f1e04d0-5580-49c3-853c-a14f6c819a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixSize = 4\n",
    "A = np.random.rand(matrixSize, matrixSize)\n",
    "B = np.dot(A, A.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "26d34038-7099-4a44-a25b-7d332edfdc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9980213 , 1.33010605, 0.45539975, 0.47717353],\n",
       "       [1.33010605, 2.06308748, 0.78415537, 0.73757189],\n",
       "       [0.45539975, 0.78415537, 0.40060215, 0.28996259],\n",
       "       [0.47717353, 0.73757189, 0.28996259, 0.26989832]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3c2de144-b9e3-4f14-a9af-aa05a152d810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7265, 0.0551],\n",
      "        [0.8841, 1.0138],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000]])\n",
      "tensor(2)\n",
      "tensor([[ 1.0000e+00, -5.9605e-08],\n",
      "        [ 1.1921e-07,  1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "psd_ratio = 1  # test how error increases as Q becomes less PSD\n",
    "d = 2\n",
    "e = 4\n",
    "l = 4\n",
    "assert l >= d\n",
    "arange_d = torch.arange(d, 0, -1)\n",
    "psd_matrix = torch.Tensor(np.random.rand(d, d))\n",
    "psd_matrix = torch.matmul(psd_matrix, psd_matrix)\n",
    "psd_matrix = torch.cat([psd_matrix, torch.zeros(l - d, d)], dim=0)\n",
    "q = torch.Tensor(np.random.rand(l, d)) * (1 - psd_ratio) + psd_matrix * psd_ratio\n",
    "q_inv = torch.linalg.pinv(q)\n",
    "k = torch.Tensor(np.random.rand(l, d)) * (1 - psd_ratio) + psd_matrix * psd_ratio\n",
    "\n",
    "q, k = q.type(torch.float), k.type(torch.float)\n",
    "\n",
    "print(q)\n",
    "print(torch.linalg.matrix_rank(q))\n",
    "print(q_inv @ q)\n",
    "#print(q @ q_inv) # not valid\n",
    "\n",
    "v = torch.Tensor(np.random.rand(l, d) / temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6376f85d-a0e7-40c5-823e-d8f1db62b4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.exp(torch.matmul(q, k.T))  # [ queries X keys ]\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c6bd3ece-c083-418b-938b-1b294726c2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42363572 0.24654444 0.43344927]\n",
      " [2.71414006 5.14193764 4.23819015]\n",
      " [0.07293728 0.37789997 0.21410929]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.42363572, 0.24654444, 0.43344927],\n",
       "       [2.71414006, 5.14193764, 4.23819015],\n",
       "       [0.07293728, 0.37789997, 0.21410929]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(3,3)\n",
    "b = np.random.rand(3, 1)\n",
    "c = a / b\n",
    "print(c)\n",
    "np.linalg.pinv(np.diag(b[:,0])) @ a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ddb2ee4a-40eb-440d-a925-2fefebbbcf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.2900e-01,  7.6752e-01, -1.2362e-01,  5.2490e-08],\n",
      "        [ 4.6785e-01, -2.4672e-01,  8.4868e-01, -3.3643e-07],\n",
      "        [ 4.3902e-01, -4.1836e-01, -3.6364e-01, -7.0711e-01],\n",
      "        [ 4.3902e-01, -4.1836e-01, -3.6364e-01,  7.0711e-01]])\n",
      "tensor([[ -0.4636,  -0.2646,      nan, -16.7626],\n",
      "        [ -0.7596,      nan,  -0.1641,      nan],\n",
      "        [ -0.8232,      nan,      nan,      nan],\n",
      "        [ -0.8232,      nan,      nan,  -0.3466]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4636,     nan,     nan,     nan],\n",
       "        [-0.7596,     nan,     nan,     nan],\n",
       "        [ 0.0000,     nan,     nan,     nan],\n",
       "        [ 0.0000,     nan,     nan,     nan]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute decomposition\n",
    "eigenvals, E = torch.linalg.eig(A)  # eigenvectors are columns of E\n",
    "eigenvals, E = eigenvals[:e], E[:,:e]  # take only e-highest eigenvectors\n",
    "Lambda = torch.diag(eigenvals)\n",
    "E = E.type(torch.float32)\n",
    "\n",
    "print(E)\n",
    "# test\n",
    "print(torch.log(E))\n",
    "(q @ (q_inv @ torch.log(E)))\n",
    "# E_hat = torch.matmul(q, torch.matmul(torch.linalg.pinv(q), torch.log(E)))\n",
    "# E_hat2 = q @ torch.linalg.lstsq(q, torch.log(E)).solution\n",
    "# print(E)\n",
    "# print(torch.exp(E_hat))\n",
    "# print(torch.exp(E_hat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "25ffee8c-159c-4374-a58f-36e0f0d7ae1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2419/674491707.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(-7.0711e-01)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(-7.0711e-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2b15af0c-c6ee-4971-9be9-64d926777e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0035+0.j, 1.0106+0.j, 1.0177+0.j, 1.0249+0.j, 1.0321+0.j],\n",
       "        [1.0106+0.j, 1.0466+0.j, 1.0840+0.j, 1.1228+0.j, 1.1628+0.j],\n",
       "        [1.0177+0.j, 1.0840+0.j, 1.1547+0.j, 1.2300+0.j, 1.3102+0.j],\n",
       "        [1.0249+0.j, 1.1228+0.j, 1.2300+0.j, 1.3475+0.j, 1.4762+0.j],\n",
       "        [1.0321+0.j, 1.1628+0.j, 1.3102+0.j, 1.4762+0.j, 1.6632+0.j]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E @ Lambda @ torch.linalg.pinv(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "41818087-550f-4b0d-acce-d34d794fdb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0035, 1.0106, 1.0177, 1.0249, 1.0321],\n",
       "        [1.0106, 1.0467, 1.0840, 1.1228, 1.1629],\n",
       "        [1.0177, 1.0840, 1.1547, 1.2300, 1.3102],\n",
       "        [1.0249, 1.1228, 1.2300, 1.3475, 1.4762],\n",
       "        [1.0321, 1.1629, 1.3102, 1.4762, 1.6632]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f6c9dde0-675d-4778-aef9-799f86d50be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.8236, 11.6055],\n",
       "        [ 3.0818,  5.9459]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0bed3-b7e2-4a27-8c6c-466dc1465e50",
   "metadata": {},
   "source": [
    "### First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2c9540fc-5cd0-4b15-87fd-84c3e3db9029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[1.7639, 1.7609, 1.1244, 1.7304, 1.3712],\n",
      "        [2.0524, 2.3596, 1.1748, 2.2233, 2.0929],\n",
      "        [2.3386, 2.5569, 1.2016, 2.4313, 1.9976],\n",
      "        [2.4823, 2.6884, 1.2155, 2.5579, 2.0196],\n",
      "        [1.7632, 2.0020, 1.1372, 1.9017, 1.8649]])\n",
      "Output:\n",
      "tensor([[3.3751, 6.1221],\n",
      "        [4.4014, 7.8028],\n",
      "        [4.6564, 8.2506],\n",
      "        [4.8488, 8.5767],\n",
      "        [3.8390, 6.8625]])\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "d = 2\n",
    "e = 5\n",
    "l = 5\n",
    "q = torch.Tensor(np.random.rand(l, d) / temp)\n",
    "k = torch.Tensor(np.random.rand(l, d) / temp)\n",
    "v = torch.Tensor(np.random.rand(l, d) / temp)\n",
    "A_pre = torch.matmul(q, k.T)\n",
    "A_norm = torch.exp(A_pre).sum(dim=1)\n",
    "#A = F.softmax(A_pre, dim=1)  # Experiment with non-normalized case\n",
    "A = torch.exp(A_pre)\n",
    "print(f\"A:\\n{A}\")\n",
    "out = torch.matmul(A, v)\n",
    "print(f\"Output:\\n{out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5f55b0b1-f782-4066-896e-13c7a3ef5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute decomposition\n",
    "eigenvals, E = torch.linalg.eig(A)  # eigenvectors are columns of E\n",
    "eigenvals, E = eigenvals[:e], E[:,:e]  # take only e-highest eigenvectors\n",
    "Lambda = torch.diag(eigenvals)\n",
    "\n",
    "# compute new k from q, eigenvectors, and normalization coefficients of original attention matrix\n",
    "#k_hat = torch.matmul(torch.linalg.pinv(q.type(torch.complex64)), torch.log(E * A_norm[:,None])).T.type(torch.float32)\n",
    "k_hat = torch.matmul(torch.linalg.pinv(q.type(torch.complex64)), torch.log(E)).T.type(torch.float32)\n",
    "\n",
    "# compute new v from v, eigenvectors, and lambda\n",
    "v_hat = torch.matmul(torch.matmul(Lambda, torch.linalg.pinv(E)), v.type(torch.complex64)).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3f3fe6d1-4867-4bd4-980c-558cbf9f8938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5776, -0.6632],\n",
      "        [-1.2459, -0.2738],\n",
      "        [-1.2459, -0.2738],\n",
      "        [-0.6523, -1.3320],\n",
      "        [-2.4310,  0.3251]])\n",
      "New A_pre:\n",
      "tensor([[-0.2907, -0.1502, -0.1502, -0.5687,  0.0613],\n",
      "        [-0.9064, -0.8535, -0.8535, -1.5790, -0.8469],\n",
      "        [-0.6065, -1.0570, -1.0570, -0.8116, -1.8760],\n",
      "        [-0.9424, -1.2057, -1.2057, -1.4811, -1.7382],\n",
      "        [-0.2090, -0.2059, -0.2059, -0.3595, -0.2197]])\n",
      "New A:\n",
      "tensor([[0.1824, 0.2100, 0.2100, 0.1382, 0.2594],\n",
      "        [0.2137, 0.2253, 0.2253, 0.1091, 0.2268],\n",
      "        [0.2967, 0.1891, 0.1891, 0.2417, 0.0834],\n",
      "        [0.2800, 0.2152, 0.2152, 0.1634, 0.1263],\n",
      "        [0.2059, 0.2066, 0.2066, 0.1772, 0.2037]])\n",
      "New Output:\n",
      "tensor([[-1.3402, -2.5358],\n",
      "        [-1.5631, -2.9675],\n",
      "        [-2.1318, -4.1095],\n",
      "        [-2.0231, -3.8810],\n",
      "        [-1.5032, -2.8593]])\n"
     ]
    }
   ],
   "source": [
    "# compute new output\n",
    "print(k_hat)\n",
    "A_pre = torch.matmul(q, k_hat.T)\n",
    "print(f\"New A_pre:\\n{A_pre}\")\n",
    "A_hat = F.softmax(torch.matmul(q, k_hat.T), dim=1)\n",
    "print(f\"New A:\\n{A_hat}\")\n",
    "out_hat = torch.matmul(A_hat, v_hat)\n",
    "print(f\"New Output:\\n{out_hat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "21076835-86ba-49a4-88ae-af758439dedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8786, -2.0016],\n",
      "        [ 0.7563, -2.1765],\n",
      "        [ 3.7824, -5.3803],\n",
      "        [ 0.4248, -2.1134],\n",
      "        [ 1.7735, -3.4110]])\n",
      "New A_pre:\n",
      "tensor([[-0.6289, -0.7102, -1.5018, -0.7308, -1.0350],\n",
      "        [-0.7243, -0.9397, -0.8613, -1.1491, -1.0233],\n",
      "        [-0.8518, -0.9481, -2.1340, -0.9545, -1.4213],\n",
      "        [-0.9654, -1.1892, -1.5990, -1.3718, -1.4515],\n",
      "        [-0.7705, -1.0297, -0.7016, -1.2984, -1.0468]])\n",
      "New A:\n",
      "tensor([[0.2558, 0.2358, 0.1069, 0.2310, 0.1704],\n",
      "        [0.2455, 0.1979, 0.2141, 0.1605, 0.1820],\n",
      "        [0.2737, 0.2486, 0.0759, 0.2470, 0.1548],\n",
      "        [0.2769, 0.2214, 0.1470, 0.1844, 0.1703],\n",
      "        [0.2386, 0.1841, 0.2556, 0.1407, 0.1810]])\n",
      "New Output:\n",
      "tensor([[-0.2635, -0.3403],\n",
      "        [-0.2533, -0.3273],\n",
      "        [-0.2822, -0.3640],\n",
      "        [-0.2861, -0.3690],\n",
      "        [-0.2463, -0.3183]])\n"
     ]
    }
   ],
   "source": [
    "# compute new output\n",
    "print(k_hat)\n",
    "A_pre = torch.matmul(q, k_hat.T)\n",
    "print(f\"New A_pre:\\n{A_pre}\")\n",
    "A_hat = F.softmax(torch.matmul(q, k_hat.T), dim=1)\n",
    "print(f\"New A:\\n{A_hat}\")\n",
    "out_hat = torch.matmul(A_hat, v_hat)\n",
    "print(f\"New Output:\\n{out_hat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ccdbb13e-3756-462e-b79a-7d0226ca0e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5063,  2.4431],\n",
       "        [-0.6286,  2.2682],\n",
       "        [ 2.3975, -0.9356],\n",
       "        [-0.9601,  2.3313],\n",
       "        [ 0.3886,  1.0337]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "de957f3a-cf74-4c21-b441-c7af2631a7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8786, -2.0016],\n",
       "        [ 0.7563, -2.1765],\n",
       "        [ 3.7824, -5.3803],\n",
       "        [ 0.4248, -2.1134],\n",
       "        [ 1.7735, -3.4110]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e0895176-688e-48e1-a6f1-af7b2d6d3967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8047, -0.6859, -1.1466, -1.7738, -2.0176],\n",
      "        [-0.8047, -1.2718, -1.1452, -0.6483, -0.7625],\n",
      "        [-0.8047, -0.6890, -2.0405, -0.2543, -0.3628],\n",
      "        [-0.8047, -1.6163, -2.1543, -1.4873, -2.2536],\n",
      "        [-0.8047, -0.4888, -0.1323, -1.5474, -0.6553]])\n",
      "tensor([[ 1.0170,  1.1358,  0.6751,  0.0479, -0.1959],\n",
      "        [ 1.3939,  0.9268,  1.0535,  1.5503,  1.4361],\n",
      "        [ 1.0563,  1.1720, -0.1795,  1.6067,  1.4981],\n",
      "        [ 1.4145,  0.6029,  0.0649,  0.7319, -0.0344],\n",
      "        [ 1.5231,  1.8391,  2.1955,  0.7804,  1.6725]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.log(E).type(torch.float))\n",
    "print(torch.log(E * A_norm[:,None]).type(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afce26c-b176-438b-88ad-6e84a8a47290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0974a87-5f27-4ca2-9752-cc4c006743d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf903b8c-eb32-41fa-8176-4dee45a010a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a23d2b63-8ca7-446b-ba5d-cf38de32c731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2128+0.j, 0.1722+0.j, 0.1904+0.j, 0.2263+0.j, 0.1984+0.j],\n",
       "        [0.2745+0.j, 0.1418+0.j, 0.1555+0.j, 0.2239+0.j, 0.2043+0.j],\n",
       "        [0.2107+0.j, 0.1659+0.j, 0.1906+0.j, 0.2363+0.j, 0.1964+0.j],\n",
       "        [0.2676+0.j, 0.1378+0.j, 0.1577+0.j, 0.2352+0.j, 0.2018+0.j],\n",
       "        [0.2957+0.j, 0.1321+0.j, 0.1449+0.j, 0.2225+0.j, 0.2048+0.j]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.matmul(E, Lambda), torch.linalg.pinv(E))  # verify this is identical to A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "01462da1-f782-4938-8db9-01eb543700c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3408+0.0000e+00j, 2.5500+8.7651e-04j, 2.2108-5.7629e-01j,\n",
       "         2.2108+5.7629e-01j, 2.0674+9.8414e-02j],\n",
       "        [4.7148+0.0000e+00j, 4.8400+9.6306e-01j, 4.5572+5.0659e-01j,\n",
       "         4.5572-5.0659e-01j, 4.6560+3.7260e-01j]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "af6a1ae3-ca63-4a44-b02a-1e309b6dfb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3408+0.0000e+00j, 2.5500+8.7655e-04j, 2.2108-5.7629e-01j,\n",
       "         2.2108+5.7629e-01j, 2.0674+9.8414e-02j],\n",
       "        [4.7148+0.0000e+00j, 4.8400+9.6306e-01j, 4.5572+5.0659e-01j,\n",
       "         4.5572-5.0659e-01j, 4.6560+3.7260e-01j]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.matmul(torch.linalg.pinv(q.type(torch.complex64)), torch.log(E * A_norm[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fbe09c65-eed9-42a5-9a51-1ebbf0934438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.9680+3.1416j,  9.6554+3.1416j,  7.7604+3.1416j],\n",
       "        [10.5996+3.1416j,  9.7819+0.0000j,  7.3967+3.1416j],\n",
       "        [14.4327+3.1416j, 14.6182+0.0000j, 14.4411+0.0000j],\n",
       "        [24.5688+3.1416j, 25.0835+0.0000j, 25.2253+0.0000j],\n",
       "        [16.8817+3.1416j, 14.9674+3.1416j, 16.1924+0.0000j]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(E * A_norm[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "17960ee0-9b78-4851-babf-442656c3beaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3275+0.0000j, 0.0615+0.5169j, 0.0615-0.5169j],\n",
       "        [2.0710+0.0000j, 3.3681-0.8383j, 3.3681+0.8383j]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_hat.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c09d4361-01e9-4424-83b7-530973639686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c626745c-3cb5-43a7-bbe0-225913ff8a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4472,  0.4465],\n",
       "        [ 0.4472,  0.4221],\n",
       "        [ 0.4472, -0.3806],\n",
       "        [ 0.4472,  0.5325],\n",
       "        [ 0.4472,  0.4406]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce4ce6-a80a-448e-bc6f-0baaa8c51153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d726ec6d-bd3b-4cca-a5a0-482872953f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
       "          0.0000+0.0000j],\n",
       "        [ 0.0000+0.0000j, -0.2225+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
       "          0.0000+0.0000j],\n",
       "        [ 0.0000+0.0000j,  0.0000+0.0000j, -0.0216+0.0310j,  0.0000+0.0000j,\n",
       "          0.0000+0.0000j],\n",
       "        [ 0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j, -0.0216-0.0310j,\n",
       "          0.0000+0.0000j],\n",
       "        [ 0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
       "          0.0255+0.0000j]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca588f-9308-4263-bcab-2c144648cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_hat = torch.linalg.lstsq(q, torch.log("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8c305-491c-4df9-894e-a270ce91fe15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cc968-9a4a-4c4e-b4e1-50bd3d5eee10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c3245-274e-41e2-b146-31c370fe347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing eigenvector dimensionality\n",
    "E, V = torch.linalg.eig(A)  # eigenvectors are columns of V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea2fc3a5-7a03-4ca0-b8e7-29352693586a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4472+0.j],\n",
       "        [-0.4472+0.j],\n",
       "        [-0.4472+0.j],\n",
       "        [-0.4472+0.j],\n",
       "        [-0.4472+0.j]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(A.type(torch.complex64), V[:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6d49409e-a281-4af5-881f-bd93a79bb50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4472+0.j],\n",
       "        [-0.4472+0.j],\n",
       "        [-0.4472+0.j],\n",
       "        [-0.4472+0.j],\n",
       "        [-0.4472+0.j]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[:,:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b720dec-df49-4587-86e5-33206737673f",
   "metadata": {},
   "source": [
    "Can we solve for k_opt from q and u_post? Initial guess: log(u_post) cross left inverse of q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e50c609a-96bd-4a33-ac18-8b4bee0865c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8213, 2.0570, 2.2274],\n",
       "        [1.0515, 2.4759, 1.7531]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d2ace19-60cb-4b3d-9367-d1deb879c4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does left inverse exist? check rank of q\n",
    "np.linalg.matrix_rank(q) == d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af140076-4e36-442f-878d-4517731612fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09949453, -0.31391796, -0.13661294],\n",
       "       [-0.6703938 ,  0.10499796, -0.61092776]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in general, q should have a left inverse\n",
    "k_est, _, _, _ = np.linalg.lstsq(q, np.log(u_post), rcond=None)\n",
    "k_est = k_est.T\n",
    "k_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13d34d4c-9b04-4439-ad7d-4d80ea1121d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8213, 2.0570, 2.2274],\n",
       "        [1.0515, 2.4759, 1.7531]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fail - let's construct normalization term from k_est and see if we can get closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ba583-e3ee-410d-b5f1-d74483542682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
