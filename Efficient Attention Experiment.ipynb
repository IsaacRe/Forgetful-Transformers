{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f65f4d-52a6-44f6-a9e5-d12da452de90",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad1b98b-fdb9-4a14-a5b4-6a12b7bef938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "import numpy as  np\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc39360-7e25-453d-8bf2-b18ade72a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "dataset = load_dataset('wikitext', 'wikitext-103-v1')\n",
    "split = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90117c1-608c-4d60-a916-f9a3f3cf1210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute text with token length >= 512\n",
    "batch = 500\n",
    "min_tok_length = 512\n",
    "filtered = []\n",
    "lengths = []\n",
    "max_length = 0\n",
    "for i in tqdm(range(0, len(split), batch)):\n",
    "    lengths += [len(tok) for tok in tokenizer.batch_encode_plus([split[min(i+j, len(split) - 1)]['text'] for j in range(batch)])['input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b6838-79a9-471c-a4ca-eb930aac10d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('token_length.npy', np.array(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2f1826e-39a3-442b-828b-fec4a264ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.load('token_length.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0222fa2a-b7b0-47d6-bd34-117ae3668b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eab667b-a181-4b5c-ae1c-748e5c189b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([len(tok) > 512 for tok in tokenizer.batch_encode_plus([split[int(i)]['text'] for i in np.where(l > 512)[0][:20]])['input_ids']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c3d056-1379-4f91-8d63-55f34dd98e5e",
   "metadata": {},
   "source": [
    "### Apply to MHA (GPT2 WikiText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd88dfa-adf2-49ca-a7fd-c3aa14674533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Attention\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import transformers_drop_in as drop_in\n",
    "import tensor_util as tu\n",
    "from config import CONFIG\n",
    "from performer_pytorch.performer_pytorch import causal_linear_attention_noncuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91a6372b-1047-4007-938e-0c3f8b817aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.do_consolidate = True\n",
    "CONFIG.consolidate_ratio = 0.5\n",
    "CONFIG.context_length = 400\n",
    "CONFIG.consolidate_length = 200\n",
    "CONFIG.temperature = 0.1\n",
    "CONFIG.fix_prune_rate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc5b9da-f169-4ba7-92f1-0b0ae94fedb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2AttentionDropIn(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2').to(CONFIG.device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b511308b-4ff1-4ce3-94ac-129fe106d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "indices, = np.where(l > CONFIG.context_length)\n",
    "batch_iter = iter(np.array_split(np.random.choice(indices, len(indices), replace=False), len(indices) // batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395deac1-0e86-4cac-a3d1-bf7ec0f0da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = 12\n",
    "drop_in.GLOBALS.outputs = {\n",
    "    'unnormalized': [[] for _ in range(n_layer)],\n",
    "    'eig': [[] for _ in range(n_layer)],\n",
    "    'final': [[] for _ in range(n_layer)],\n",
    "    'value': [[] for _ in range(n_layer)],\n",
    "    'query': [[] for _ in range(n_layer)],\n",
    "    'key': [[] for _ in range(n_layer)],\n",
    "    'out': [[] for _ in range(n_layer)],\n",
    "    'mask': [[] for _ in range(n_layer)],\n",
    "}\n",
    "def record_attn(layer_idx, query, key, value, unnormalized_attn, final_attn, attn_output, attn_mask):\n",
    "    drop_in.GLOBALS.outputs['unnormalized'][layer_idx] += [unnormalized_attn.cpu()]\n",
    "    drop_in.GLOBALS.outputs['final'][layer_idx] += [final_attn.cpu()]\n",
    "    drop_in.GLOBALS.outputs['value'][layer_idx] += [value.cpu()]\n",
    "    drop_in.GLOBALS.outputs['query'][layer_idx] += [value.cpu()]\n",
    "    drop_in.GLOBALS.outputs['key'][layer_idx] += [value.cpu()]\n",
    "    drop_in.GLOBALS.outputs['out'][layer_idx] += [attn_output.cpu()]\n",
    "    drop_in.GLOBALS.outputs['mask'][layer_idx] += [attn_mask.cpu()]\n",
    "\n",
    "def no_op(query, key, value, attn_weights):\n",
    "    pass\n",
    "\n",
    "drop_in.record_attn_vars = record_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b762f222-4d0b-450f-9ab6-d14ea3f153d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a150600d6934def936478357c332e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drop_in.GLOBALS.scaling_enabled = False\n",
    "n_sample = 1\n",
    "n_layer = 12\n",
    "cols = 4\n",
    "rows = n_layer // cols\n",
    "rank_by_layer = [[] for _ in range(n_layer)]\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(n_sample)):\n",
    "        batch = next(batch_iter)\n",
    "        model_input = {name: t.to(CONFIG.device) for name, t in tokenizer.batch_encode_plus(split[batch]['text'],\n",
    "                                                                                         return_tensors=\"pt\",\n",
    "                                                                                         truncation=True,\n",
    "                                                                                         max_length=CONFIG.context_length).items()}\n",
    "        model(**model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1f6272c-2db8-4918-a20b-8dde95dab9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for m in ['key', 'query', 'value', 'out', 'mask']:\n",
    "    data[m] = torch.stack([torch.cat(t, dim=0) for t in drop_in.GLOBALS.outputs[m]], dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b37cc729-19fe-4398-8197-5e61e28a7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_linear_attn(q, k, v):\n",
    "    return causal_linear_attention_noncuda(\n",
    "        torch.softmax(q, dim=-1),\n",
    "        torch.exp(k),\n",
    "        v,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b6b97da-726a-4328-9d4f-b21e207f369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = slice(None), slice(None)\n",
    "q = data['query'][idx]\n",
    "k = data['key'][idx]\n",
    "v = data['value'][idx]\n",
    "raw = q @ k.transpose(-2, -1)\n",
    "mask = torch.tril(torch.ones_like(raw, dtype=torch.bool), diagonal=0).transpose(-2, -1)\n",
    "raw[~mask] = -float(\"inf\")\n",
    "attn = torch.softmax(raw, dim=-1)\n",
    "out = attn @ v\n",
    "out_p = compute_linear_attn(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74a3c71b-43b5-47dc-87c8-c0b514c07d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.460476"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((out - out_p)**2).sum(dim=-1)**0.5).numpy().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
