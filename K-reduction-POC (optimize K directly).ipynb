{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa24bdcb-cfe5-4e1b-aa1c-4c15a0fc965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c1223-c295-42f4-a848-75fa3d6fdfaf",
   "metadata": {},
   "source": [
    "### Load Q, K, V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94278971-0668-4fed-a4e1-4bd29861bde5",
   "metadata": {},
   "source": [
    "Generate random test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d3c0b69a-05eb-47ae-a5fe-7007f8d2085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_ratio = 1  # test how error increases as Q becomes less PSD\n",
    "d = 64\n",
    "e = 400\n",
    "l = 400\n",
    "batch = 10\n",
    "seed = 12\n",
    "assert l >= d\n",
    "if seed:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "arange_d = torch.arange(d, 0, -1)\n",
    "psd_matrix = torch.Tensor(np.random.rand(d, d))\n",
    "psd_matrix = torch.matmul(psd_matrix, psd_matrix)\n",
    "psd_matrix = torch.cat([psd_matrix, torch.ones(l - d, d)], dim=0)\n",
    "q = torch.Tensor(np.random.rand(l, d)) * (1 - psd_ratio) + psd_matrix * psd_ratio\n",
    "k = torch.Tensor(np.random.rand(l, d)) * (1 - psd_ratio) + psd_matrix * psd_ratio\n",
    "\n",
    "# make sure query vectors are not all zero (creates large error when solving for K_hat, and will never occur in practice)\n",
    "\n",
    "q, k = q.type(torch.float), k.type(torch.float)\n",
    "v = torch.Tensor(np.random.rand(l, d))\n",
    "\n",
    "q, k, v = q[None].repeat(batch, 1, 1), k[None].repeat(batch, 1, 1), v[None].repeat(batch, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065207c4-b0e6-4efd-98f7-05066e374f90",
   "metadata": {},
   "source": [
    "Or load q, k, v from GPT-2 run on WMT (see end of notebook for data collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6178177e-bf03-4567-9d36-7f18f2f082d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 400\n",
    "\n",
    "qkv = np.load('qkv.npz')\n",
    "n_layer, n_sample, n_attn_heads, l, d = qkv['q'].shape  # [ layers X samples X attention heads X tokens X q dimension ]\n",
    "\n",
    "sample_dims = np.random.randint(0, n_sample * n_attn_heads, (n_layer,))\n",
    "sample_mask = torch.zeros(n_layer, n_sample * n_attn_heads).type(torch.bool)\n",
    "sample_mask[np.arange(n_layer), sample_dims] = True\n",
    "\n",
    "# sample along sample and attention head dimensions\n",
    "q, k, v = (\n",
    "    torch.Tensor(qkv[n]).reshape(n_layer, n_sample * n_attn_heads, l, d)[sample_mask]\n",
    "    for n in ('q', 'k', 'v')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0e645-cf20-46cf-9797-d46cda2d0600",
   "metadata": {},
   "source": [
    "### Run decomposition\n",
    "Approximate within-softmax QK decomposition to bring dimensionality reduction outside softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82ff216f-42ba-4511-a513-02ebfb933175",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ = q @ k.transpose(-1, -2)\n",
    "A = torch.softmax(A_, dim=-1)\n",
    "out = A @ v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620b399-8d79-48b8-804e-b163facbc64a",
   "metadata": {},
   "source": [
    "### Try directly optimizging k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6575a892-b9ee-4984-b1c3-0a174d149a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed08d0b0-95a4-4f2d-a805-735c44bc1c2f",
   "metadata": {},
   "source": [
    "#### Train on L2 of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28acd889-2513-41ea-85da-efc7f2cd09f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96331e73f01f478bb6f92be1de2a159b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K_hat = torch.nn.Parameter(torch.zeros_like(k))\n",
    "V_hat = torch.nn.Parameter(torch.zeros_like(v))\n",
    "K_hat.data.normal_()\n",
    "V_hat.data.normal_()\n",
    "\n",
    "n_steps = 10000\n",
    "optim = torch.optim.SGD([K_hat, V_hat], lr=0.2)\n",
    "for i in (pbar := tqdm(range(n_steps))):\n",
    "    loss = (((torch.softmax(q @ K_hat.transpose(-2, -1), dim=-1) @ V_hat) - out) ** 2).sum(dim=-1).mean()\n",
    "    pbar.set_description(f\"loss: {loss.item()}\")\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5d6d25-71a7-4671-9dee-3881e905f27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5124, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((out - (torch.softmax(q @ K_hat.transpose(-2, -1), dim=-1) @ V_hat)) ** 2).sum(dim=-1) ** 0.5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62df932b-88ff-42e4-afc2-b687bf8d8595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8247, 2.4484, 1.2301, 2.6702, 2.8354, 3.1484, 3.1039, 2.6023, 4.3469,\n",
      "        3.0779, 1.3841, 2.4769])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(((((out - (torch.softmax(q @ K_hat.transpose(-2, -1), dim=-1) @ V_hat)) ** 2).sum(dim=-1) ** 0.5).mean(dim=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d1f9f-7671-48a8-868e-0bd48e2f6f40",
   "metadata": {},
   "source": [
    "#### Train on X-entropy of attention matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d549cab7-71f6-49fb-9ed7-50f7613f6e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b8b11b9-f92d-4cfd-9ac6-50c52d45af4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 400, 400])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33e62925-32c7-47ab-a3aa-34c24fec5f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bd8b4fe2ce41f6b572a7f5346e98fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m (pbar \u001b[38;5;241m:=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(n_steps))):\n\u001b[1;32m     10\u001b[0m     A__hat \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m K_hat\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA__hat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers/lib/python3.11/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/transformers/lib/python3.11/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K_hat = torch.nn.Parameter(torch.zeros_like(k))\n",
    "V_hat = torch.nn.Parameter(torch.zeros_like(v))\n",
    "K_hat.data.normal_()\n",
    "V_hat.data.normal_()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_steps = 10000\n",
    "optim = torch.optim.SGD([K_hat, V_hat], lr=1)\n",
    "for i in (pbar := tqdm(range(n_steps))):\n",
    "    A__hat = q @ K_hat.transpose(-2, -1)\n",
    "    loss = loss_fn(A__hat.reshape(-1, 400), A_.reshape(-1, 400))\n",
    "    pbar.set_description(f\"loss: {loss.item()}\")\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b7087-e1b4-470d-a880-02efb133b4dc",
   "metadata": {},
   "source": [
    "### Try solving for original V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "c096fccf-b8d9-4ae0-991e-69979f54e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.softmax(q @ k.transpose(-1, -2), dim=-1)\n",
    "#A[...,~attn_mask] = 0\n",
    "out = A @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "73b9cf5e-f0f2-4671-894b-99fed9ed2500",
   "metadata": {},
   "outputs": [
    {
     "ename": "_LinAlgError",
     "evalue": "torch.linalg.solve: (Batch element 4): The solver failed because the input matrix is singular.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_LinAlgError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[381], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m v__ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msolution\n",
      "\u001b[0;31m_LinAlgError\u001b[0m: torch.linalg.solve: (Batch element 4): The solver failed because the input matrix is singular."
     ]
    }
   ],
   "source": [
    "v__ = torch.linalg.solve(A, out).solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "807eaed7-bab1-471a-96f2-6e89c75a0b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1046, 3.6361, 2.5274, 3.0096, 3.0790, 3.1536, 2.8280, 0.6648, 5.4319,\n",
      "        4.6320, 8.5844, 1.8041])\n"
     ]
    }
   ],
   "source": [
    "print((((out - A @ v__) ** 2).sum(dim=-1) ** 0.5).mean(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "b530ac36-e382-4b1a-895d-ac47115bf4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9714, 0.4000, 0.0071, 0.0422, 0.0416, 0.2649, 0.3864, 0.3217, 0.1348,\n",
      "        0.7272, 0.0907, 1.4685])\n"
     ]
    }
   ],
   "source": [
    "print((((out) ** 2).sum(dim=-1) ** 0.5).mean(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "59d335c3-efd5-4345-a48a-24663940b3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f156d605c9324b649fa43c8974f8847b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V_hat = torch.nn.Parameter(torch.zeros_like(v))\n",
    "V_hat.data.normal_()\n",
    "\n",
    "n_steps = 10000\n",
    "optim = torch.optim.SGD([V_hat], lr=0.2)\n",
    "for i in (pbar := tqdm(range(n_steps))):\n",
    "    loss = (((A @ V_hat) - out) ** 2).sum(dim=-1).mean()\n",
    "    pbar.set_description(f\"loss: {loss.item()}\")\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "e3718141-7361-4709-88ac-8d05905f5679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8189, 0.9440, 0.4758, 0.5052, 0.4074, 0.7642, 0.8565, 0.3587, 0.4798,\n",
      "        0.4630, 0.8575, 0.4125])\n"
     ]
    }
   ],
   "source": [
    "print((((out - A @ V_hat) ** 2).sum(dim=-1) ** 0.5).mean(dim=-1).detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b9157-2e91-4302-8ddc-59133b40136b",
   "metadata": {},
   "source": [
    "### Try solving for V_hat after within-softmax decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138b9e5-7e61-4948-85be-3e4631f5f79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d94c778d-57bf-4ec5-b269-563b2edaf01a",
   "metadata": {},
   "source": [
    "### Continue decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "ff0bfc19-e2a1-4dfe-a291-d3f10b3c4364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21.6346, 17.7610, 22.2047, 16.8955, 20.1448, 18.2865, 19.0530, 11.2748,\n",
      "        21.1698, 21.8627, 19.5552, 12.5265])\n",
      "tensor([18.3572, 15.5771, 18.5209, 14.5647, 16.5345, 15.0256, 15.5906,  9.5470,\n",
      "        17.5020, 17.3379, 16.1797, 10.2331])\n",
      "tensor([17.6073, 15.0833, 17.5408, 13.9145, 15.2176, 13.6837, 14.0984,  9.5459,\n",
      "        16.0747, 15.3922, 14.6954,  9.6832])\n",
      "tensor([18.0905, 15.5026, 17.8915, 14.1389, 15.0216, 13.3313, 13.6019, 10.3054,\n",
      "        15.7617, 14.7003, 14.1734,  9.9381])\n"
     ]
    }
   ],
   "source": [
    "# solve for K_hat - may find different solutions to same q, US_ due to randomness (even after seeding)\n",
    "# overdetermined system when l > d (always) - the larger the offset the worse the solution\n",
    "# optimal offset around 1.3 (balance pos/neg post-log values)\n",
    "xs = np.arange(0.1, 0.5, 0.1)\n",
    "for x in xs:\n",
    "    K_hat = torch.linalg.lstsq(q, torch.log(US + 1 + x)).solution.transpose(-1, -2)\n",
    "    print(((torch.log(US + 1 + x) - q @ K_hat.transpose(-1, -2)) ** 2).sum(dim=-1).sum(dim=-1) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "eb53dc3c-0b97-4e3c-9f71-824e11ca47af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0236, 0.0096, 0.0018, 0.0065, 0.0039, 0.0104, 0.0137, 0.0076, 0.0074,\n",
       "        0.0147, 0.0082, 0.0105])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recompute A prime\n",
    "A_hat_p = torch.softmax(q @ K_hat.transpose(-1, -2), dim=-1)\n",
    "((A_hat - A_hat_p) ** 2).sum(dim=-1).sum(dim=-1) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "bfa1f010-2159-49b6-ba1b-25dc61831027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
       "         0.0002, 0.0002, 0.0002]),\n",
       " tensor([12.2878,  4.9760,  0.9185,  3.3771,  2.0346,  5.3996,  7.1118,  3.9255,\n",
       "          3.8505,  7.6451,  4.2630,  5.4825]),\n",
       " tensor([12.2878,  4.9760,  0.9185,  3.3771,  2.0346,  5.3996,  7.1118,  3.9255,\n",
       "          3.8505,  7.6451,  4.2630,  5.4825]))"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruct original attention matrix\n",
    "A_p = (A_hat @ D) * rowsum[:,:,None] - M_offset @ D\n",
    "A_pp = (A_hat_p @ D) * rowsum[:,:,None] - M_offset @ D\n",
    "(\n",
    "    ((A - A_p) ** 2).sum(dim=-1).sum(dim=-1) ** 0.5,\n",
    "    ((A - A_pp) ** 2).sum(dim=-1).sum(dim=-1) ** 0.5,\n",
    "    ((A_p - A_pp) ** 2).sum(dim=-1).sum(dim=-1) ** 0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "876b8d6e-2250-44ec-877a-cae3087891ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.7750e-05, 4.2608e-05, 9.9115e-05, 4.0284e-05, 4.5616e-05, 7.7316e-05,\n",
       "         6.4753e-05, 8.6857e-05, 6.2070e-05, 9.1452e-05, 1.0988e-04, 1.2083e-04]),\n",
       " tensor([0.9489, 0.8771, 0.0253, 0.1572, 0.2246, 0.3211, 0.7626, 0.1703, 0.4477,\n",
       "         1.1651, 0.2970, 1.0703]),\n",
       " tensor([0.9489, 0.8771, 0.0253, 0.1572, 0.2246, 0.3211, 0.7626, 0.1703, 0.4477,\n",
       "         1.1651, 0.2970, 1.0703]))"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute new outputs\n",
    "out_p = (A_hat @ V_hat) * rowsum[:,:,None] + output_offset\n",
    "out_pp = (A_hat_p @ V_hat) * rowsum[:,:,None] + output_offset\n",
    "(\n",
    "    (((out - out_p) ** 2).sum(dim=-1) ** 0.5).mean(dim=-1),\n",
    "    (((out - out_pp) ** 2).sum(dim=-1) ** 0.5).mean(dim=-1),\n",
    "    (((out_p - out_pp) ** 2).sum(dim=-1) ** 0.5).mean(dim=-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9f75be31-38c8-4412-acdc-d238140aa671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9714, 0.4000, 0.0071, 0.0422, 0.0416, 0.2649, 0.3864, 0.3217, 0.1348,\n",
       "        0.7272, 0.0907, 1.4685])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((out) ** 2).sum(dim=-1) ** 0.5).mean(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e036c4-e057-44e8-990f-37905f9f17bf",
   "metadata": {},
   "source": [
    "### Potential issues\n",
    "- Recomputing softmax for A_pp without original scaling factor of A_p\n",
    "- Scaling in alpha and inverse alpha at different points where they dont cancel\n",
    "- All-zero query vectors will make solving for K_hat ineffective\n",
    "- Q x K_hat = A_hat is overdetermined for K_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78396596-2e2b-43a8-a1ae-8ec9a530ae22",
   "metadata": {},
   "source": [
    "### Collect Q, K, V from WMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71ac0f3-db81-4c12-8063-052690a0b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "import numpy as  np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Attention\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import transformers_drop_in as drop_in\n",
    "import tensor_util as tu\n",
    "from config import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef08ad30-8c90-49d1-a6ee-6be515144c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.do_consolidate = True\n",
    "CONFIG.consolidate_ratio = 0.5\n",
    "CONFIG.context_length = 400\n",
    "CONFIG.consolidate_length = 200\n",
    "CONFIG.temperature = 0.1\n",
    "CONFIG.fix_prune_rate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fad639a-0b9e-49a4-ac1f-ed778d8cfc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "dataset = load_dataset('wikitext', 'wikitext-103-v1')\n",
    "split = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024d48d1-ae7a-4aad-80ef-208dfb60c2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.load('token_length.npy')\n",
    "all([len(tok) > 512 for tok in tokenizer.batch_encode_plus([split[int(i)]['text'] for i in np.where(l > 512)[0][:20]])['input_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a78f50-914d-41a7-94ad-d694ef44f4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2AttentionDropIn(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2').to(CONFIG.device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c386258d-c93e-474d-8653-ab978c1c627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "indices, = np.where(l > CONFIG.context_length)\n",
    "batch_iter = iter(np.array_split(np.random.choice(indices, len(indices), replace=False), len(indices) // batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4bef317-d5fc-4df1-824c-ee58d327b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = 12\n",
    "drop_in.GLOBALS.outputs = {\n",
    "    'q': [[] for _ in range(n_layer)],\n",
    "    'k': [[] for _ in range(n_layer)],\n",
    "    'v': [[] for _ in range(n_layer)],\n",
    "}\n",
    "\n",
    "def record_attn(layer_idx, query, key, value, unnormalized_attn, final_attn, attn_output, attn_mask):\n",
    "    drop_in.GLOBALS.outputs['q'][layer_idx] += [query.cpu()]\n",
    "    drop_in.GLOBALS.outputs['k'][layer_idx] += [key.cpu()]\n",
    "    drop_in.GLOBALS.outputs['v'][layer_idx] += [value.cpu()]\n",
    "\n",
    "\n",
    "def no_op(query, key, value, attn_weights):\n",
    "    pass\n",
    "\n",
    "drop_in.record_attn_vars = record_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f621d67-e470-41b3-b91c-54f43ab9641e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88752e9844a24a61aeb77b5989ee5cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_sample = 20\n",
    "n_layer = 12\n",
    "cols = 4\n",
    "rows = n_layer // cols\n",
    "rank_by_layer = [[] for _ in range(n_layer)]\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(n_sample)):\n",
    "        batch = next(batch_iter)\n",
    "        model_input = {name: t.to(CONFIG.device) for name, t in tokenizer.batch_encode_plus(split[batch]['text'],\n",
    "                                                                                         return_tensors=\"pt\",\n",
    "                                                                                         truncation=True,\n",
    "                                                                                         max_length=CONFIG.context_length).items()}\n",
    "        model(**model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4960fe50-6dbc-49bf-9137-bda4dc132431",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = {\n",
    "    'q': [None for _ in range(n_layer)],\n",
    "    'k': [None for _ in range(n_layer)],\n",
    "    'v': [None for _ in range(n_layer)],\n",
    "}\n",
    "for m in ['q', 'k', 'v']:\n",
    "    for i in range(n_layer):\n",
    "        qkv[m][i] = torch.cat(drop_in.GLOBALS.outputs[m][i], dim=0)\n",
    "    qkv[m] = np.stack(qkv[m], axis=0)\n",
    "np.savez('qkv.npz', **qkv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da44da-12f0-4f5c-8a86-7706076b0c09",
   "metadata": {},
   "source": [
    "### SVD from eigen decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8d2f51c8-628f-4116-a972-4e1832f06346",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, D = torch.linalg.svd(A)\n",
    "val, vec = torch.linalg.eig(A @ A.transpose(-1, -2))\n",
    "val_, vec_ = torch.linalg.eig(A.transpose(-1, -2) @ A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5071a6a5-75e8-44b2-bdbe-1f06dc3675c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([16.6662, 15.0797, 14.3649, 13.5416, 12.0955, 10.6551,  8.5561,  7.0162,\n",
       "          6.6288,  5.9499]),\n",
       " tensor([16.6662+0.j, 15.0797+0.j, 14.3649+0.j, 13.5416+0.j, 12.0956+0.j, 10.6551+0.j,\n",
       "          8.5561+0.j,  7.0162+0.j,  6.6288+0.j,  5.9499+0.j]),\n",
       " tensor([16.6662+0.j, 15.0797+0.j, 14.3649+0.j, 13.5416+0.j, 12.0956+0.j, 10.6551+0.j,\n",
       "          8.5561+0.j,  7.0162+0.j,  6.6288+0.j,  5.9500+0.j]))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0][:10]**2, val[0][:10], val_[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e0bd06dc-53e8-4061-9094-cd386c97becc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.1310e-03, -1.3311e-04,  5.6899e-04, -1.0748e-03,  2.4993e-03],\n",
       "         [ 2.5153e-02,  2.7871e-03,  1.7440e-02, -7.4674e-04,  1.2350e-01],\n",
       "         [ 1.9880e-03, -2.5313e-05,  3.4438e-04, -9.2611e-05,  3.1835e-03],\n",
       "         [ 7.2101e-03, -1.0660e-02,  1.3801e-03, -1.3957e-03,  5.7525e-03],\n",
       "         [ 6.1774e-03, -3.2167e-03,  5.2106e-04, -1.2708e-03,  7.1740e-03]]),\n",
       " tensor([[-1.1311e-03+0.j, -1.3302e-04+0.j, -5.6890e-04+0.j,  1.0750e-03+0.j],\n",
       "         [-2.5153e-02+0.j,  2.7869e-03+0.j, -1.7440e-02+0.j,  7.4698e-04+0.j],\n",
       "         [-1.9880e-03+0.j, -2.5305e-05+0.j, -3.4451e-04+0.j,  9.2737e-05+0.j],\n",
       "         [-7.2097e-03+0.j, -1.0660e-02+0.j, -1.3800e-03+0.j,  1.3958e-03+0.j],\n",
       "         [-6.1774e-03+0.j, -3.2167e-03+0.j, -5.2106e-04+0.j,  1.2708e-03+0.j]]))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[0][:5,:5], vec[0][:5,:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
